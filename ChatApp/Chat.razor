@page "/chat"
@using ChatApp.Models
@using ChatApp.Models.Responses
@using Markdig
@using Microsoft.JSInterop
@using MudBlazor
@using System.Net.Http.Headers
@inject HttpClient Http
@inject IJSRuntime JS
@inject IConfiguration Configuration


<style>
    /* Make the text within MudListItems selectable */
    .selectable-text {
        user-select: text; /* Enable text selection */
        cursor: text; /* Change the cursor to text selection cursor */
    }
</style>

<MudStack Class="p-4" Spacing="4">
    <MudText Typo="Typo.body1">
        Messages:
    </MudText>

    <MudList T="string" Selectable>
        @foreach (var message in messages)
        {
            <MudListItem T="string" Class="selectable-text" high Ripple="false">
                @if (message.IsUser)
                {
                    @($"{message.Role}:") @(new MarkupString(Markdown.ToHtml(message.Content)))
                }
                else
                {
                    @($"{message.Role}:") @(new MarkupString(Markdown.ToHtml(message.Content)))
                }
            </MudListItem>
        }
    </MudList>

    <MudTextField @bind-Value="userInput" Label="Enter your message" AutoGrow="true"/>

    <!-- Select API Provider -->
    <MudSelect T="string" Label="Select Provider" @bind-Value="selectedProvider" >
        @foreach (KeyValuePair<string, Provider> kvp in Configuration.Get<Dictionary<string, Provider>>() ?? [])
        {
            <MudSelectItem T="string" Value=@kvp.Key>@kvp.Key</MudSelectItem>
        }
    </MudSelect>

    <!-- Select Model Based on Provider 

        dynamic load the models from config
        Configuration[OpenAI:Models]

    -->

    <MudSelect T="string" Label="Select Model" @bind-Value="selectedModel">
        @foreach (string model in Configuration.GetSection($"{selectedProvider}:Models")?.Get<string[]>() ?? [])
        {
            <MudSelectItem T="string" Value=@model>@model</MudSelectItem>
        }
    </MudSelect>

    <MudButton OnClick="SendMessage" Color="Color.Primary">Send</MudButton>
</MudStack>

@code {
    private List<Message> messages = new List<Message>();
    private string userInput = string.Empty;

    private string selectedProvider = "OpenAI";  // Default provider
    private string previousProvider;


    private string selectedModel = "gpt-3.5-turbo";  // Default OpenAI model

    private Dictionary<string, string> apiKeys;
    private Dictionary<string, string> apiEndpoints;

    // Initialize API keys and endpoints
    protected override void OnInitialized()
    {
        apiKeys = new Dictionary<string, string>
        {
            { "OpenAI", Configuration["OpenAI:ApiKey"] },
            { "Claude", Configuration["Claude:ApiKey"] },
            { "LMStudio", Configuration["LMStudio:ApiKey"] }
        };

        apiEndpoints = new Dictionary<string, string>
        {
            { "OpenAI", Configuration["OpenAI:Endpoint"] },
            { "Claude", Configuration["Claude:Endpoint"] },
            { "LMStudio", Configuration["LMStudio:Endpoint"] }
        };
    }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if(previousProvider != selectedProvider)
        {
            previousProvider = selectedProvider;
            selectedModel = Configuration.GetSection($"{selectedProvider}:Models")?.Get<string[]>()?.FirstOrDefault() ?? "None";
            StateHasChanged();
        }

        await JS.InvokeVoidAsync("highlightCode");
    }

    private async Task SendMessage()
    {
        // Validate input
        if (string.IsNullOrEmpty(userInput)) return;

        // Fetch API key and endpoint for the selected provider
        var apiKey = apiKeys[selectedProvider];
        var endpoint = apiEndpoints[selectedProvider];

        try
        {
            // Send the message and get a reply
            var botReply = await SendMessageAsync(userInput, apiKey, selectedProvider, selectedModel, endpoint);

            // Add the user message and bot reply to the message list
            messages.Add(new Message { Role = "User", Content = userInput });
            messages.Add(new Message { Role = "Bot", Content = botReply });

            // Clear the user input after message is sent
            userInput = string.Empty;
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Error sending message: {ex.Message}");
        }
    }

    private async Task<string> SendMessageAsync(string userInput, string apiKey, string provider, string model, string endpoint)
    {
        // Switch provider and call respective API
        switch (provider)
        {
            case "OpenAI":
                return await SendMessageToOpenAIAsync(userInput, apiKey, model, endpoint);
            case "Claude":
                return await SendMessageToClaudeAsync(userInput, apiKey, model, endpoint);
            case "LMStudio":
                return await SendMessageToLMStudioAsync(userInput, endpoint);
            default:
                throw new ArgumentException("Unknown provider specified");
        }
    }

    // Sends messages to OpenAI or Claude API
    private async Task<string> SendMessageToOpenAIAsync(string userInput, string apiKey, string model, string endpoint)
    {
        var request = new
        {
            model = model,
            messages = new[] { new Message { Role = "user", Content = userInput } }
        };

        var httpRequestMessage = new HttpRequestMessage(HttpMethod.Post, endpoint)
        {
            Content = JsonContent.Create(request)
        };

        if (!string.IsNullOrEmpty(apiKey))
        {
            httpRequestMessage.Headers.Add("Authorization", $"Bearer {apiKey}");
        }

        try
        {
            var response = await Http.SendAsync(httpRequestMessage);
            var result = await response.Content.ReadFromJsonAsync<OpenAIResponse>();
            return result?.choices?[0]?.message?.content ?? "No response received.";
        }
        catch(Exception e)
        {
            return $"An error occurred while sending the request: {e.Message}";
        }

    }

    private async Task<string> SendMessageToClaudeAsync(string userInput, string apiKey, string model, string endpoint)
    {
        // Request structure for Claude's API
        var request = new
        {
            prompt = userInput,  // The prompt to send to Claude
            model = model,  // Model selection, e.g., "claude-v1" or "claude-v2"
            max_tokens_to_sample = 1000,  // Maximum tokens to generate
            stop_sequences = new string[] { "\n" },  // Optional stop sequences
            temperature = 0.7  // Optional temperature setting for response diversity
        };

        var httpRequestMessage = new HttpRequestMessage(HttpMethod.Post, endpoint)
        {
            Content = JsonContent.Create(request)
        };

        // Add the API key to the request header
        if (!string.IsNullOrEmpty(apiKey))
        {
            httpRequestMessage.Headers.Add("x-api-key", apiKey);  // Add the API key header
            httpRequestMessage.Headers.Add("anthropic-version", "2023-06-01");  // Specify the Anthropic version
           
        }

        httpRequestMessage.Content.Headers.ContentType = new MediaTypeHeaderValue("application/json");


        // TODO fix credits too low on anthropic



        try
        {
            // Send the request
            var response = await Http.SendAsync(httpRequestMessage);

            // Read and deserialize the response
            var result = await response.Content.ReadFromJsonAsync<ClaudeResponse>();

            // Return the generated completion (response)
            return result?.completion ?? "No response received.";
        }
        catch (Exception e)
        {
            // Handle any errors during the request
            return $"An error occurred while sending the request: {e.Message}";
        }
    }

    // Sends messages to LMStudio (local model)
    private async Task<string> SendMessageToLMStudioAsync(string userInput, string endpoint)
    {
        var request = new
        {
            prompt = userInput,
            max_tokens = 1000
        };

        var httpRequestMessage = new HttpRequestMessage(HttpMethod.Post, endpoint)
        {
            Content = JsonContent.Create(request)
        };

        var response = await Http.SendAsync(httpRequestMessage);
        response.EnsureSuccessStatusCode();

        var result = await response.Content.ReadFromJsonAsync<LMStudioResponse>();
        return result?.result ?? "No response received.";
    }

    private List<string> Providers = 
    [
        "OpenAI",
        "Claude",
        "LMStudio"
    ];
}
